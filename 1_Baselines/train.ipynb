{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch, torchvision\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "## Training Consts\n",
    "MODEL_DIR = ''\n",
    "MODEL_NAMES = ['vgg','densenet']\n",
    "DEVICE = torch.device('cpu')  ### CHANGE THIS!!!!!!!!!\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "## Data Handling Consts\n",
    "HAM_DIR = '/Users/cz/Desktop/S3 CV/Project/[C]HAM10000'\n",
    "ALL_IMG_FPS = [os.path.join(HAM_DIR,'Train',f) for f \\\n",
    "               in os.listdir(os.path.join(HAM_DIR,'Train'))]\n",
    "ALL_IMG_IDS = [os.path.splitext(os.path.basename(f))[0] \\\n",
    "               for f in ALL_IMG_FPS]\n",
    "\n",
    "IMG_SIZE = 224\n",
    "NORM_MEAN = [0.7630423088417134, 0.5456486014607426, 0.5700468609021178]\n",
    "NORM_STD = [0.0891409288333237, 0.11792632289606514, 0.1324623088597418]\n",
    "CLASSES_TO_FULLNAMES = {\n",
    "    'NV': 'Melanocytic nevi',\n",
    "    'MEL': 'dermatofibroma',\n",
    "    'BKL': 'Benign keratosis-like lesions ',\n",
    "    'BCC': 'Basal cell carcinoma',\n",
    "    'AKIEC': 'Actinic keratoses',\n",
    "    'VASC': 'Vascular lesions',\n",
    "    'DF': 'Dermatofibroma'\n",
    "}\n",
    "CLASSES = ['MEL','NV','BCC','AKIEC','BKL','DF','VASC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Data Methods and Containers\n",
    "class HAM10k(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        X = Image.open(self.df['path'].iloc[idx])\n",
    "        y = torch.tensor(int(self.df['label'].iloc[idx]))\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        return X, y\n",
    "        \n",
    "\n",
    "### Instantiate Data Constants\n",
    "# Datasets\n",
    "df_dict = {'id': [], 'label': [], 'path': []}\n",
    "with open(os.path.join(HAM_DIR,'Labels.csv'),'r') as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx == 0: continue\n",
    "        line = line.rstrip()\n",
    "        comps = line.split(',')\n",
    "        for i in range(1,8):\n",
    "            if '1' in comps[i]:\n",
    "                df_dict['label'].append(i-1)\n",
    "                break\n",
    "        df_dict['id'].append(comps[0])\n",
    "        df_dict['path'].append(os.path.join(HAM_DIR,'Train',comps[0] + '.jpg'))\n",
    "DF = pd.DataFrame(df_dict); \n",
    "\n",
    "train_ids = []\n",
    "with open(os.path.join(HAM_DIR,'TrainSplits','train.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        train_ids.append(line.rstrip())\n",
    "TRAIN_DF = DF.loc[DF['id'].isin(train_ids)]\n",
    "# train_transform = transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "#                                       transforms.RandomHorizontalFlip(),\n",
    "#                                       transforms.RandomVerticalFlip(),\n",
    "#                                       transforms.RandomRotation(20),\n",
    "#                                       transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "#                                       transforms.ToTensor(), \n",
    "#                                       transforms.Normalize(NORM_MEAN, NORM_STD)])\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "TRAIN_SET = HAM10k(TRAIN_DF, train_transform)\n",
    "\n",
    "val_ids = []\n",
    "with open(os.path.join(HAM_DIR,'TrainSplits','val.txt'),'r') as f:\n",
    "    for line in f:\n",
    "        val_ids.append(line.rstrip())\n",
    "val_transform = transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(NORM_MEAN, NORM_STD)])\n",
    "VAL_DF = DF.loc[DF['id'].isin(val_ids)]\n",
    "VAL_SET = HAM10k(VAL_DF, val_transform)\n",
    "\n",
    "\n",
    "# Cleanup\n",
    "del df_dict, train_ids, val_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Functions\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Model specific variables\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"vgg\": #VGG w/BN\n",
    "        # model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        model_ft = models.vgg11_bn()\n",
    "        model_ft.load_state_dict(torch.load(os.path.join('.','Models','vgg11_bn.pth')))\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "    elif model_name == \"densenet\": # Dense-121\n",
    "        # model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        model_ft = models.densenet121()\n",
    "        model_ft.load_state_dict(torch.load(os.path.join('.','Models','densenet121.pth')))\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        sys.exit()\n",
    "    return model_ft, input_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Functions: Train, Keep Stats, Evaluate\n",
    "\n",
    "def train_model(train_loader, model, criterion, optimizer,\n",
    "                epochs=10, tracker=None):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'=========\\nTraining Epoch {epoch+1}\\n========\\n')\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            images = Variable(images).to(DEVICE)\n",
    "            labels = Variable(labels).to(DEVICE)\n",
    "            N = images.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            \n",
    "            # Print status\n",
    "            if i % 100 == 0:\n",
    "                tacc = prediction.eq(labels.view_as(prediction)).sum().item()/N\n",
    "                print(f'[Epoch {epoch+1}], [Iter {i+1}/{len(train_loader)+1}], '\n",
    "                      f'[TrnLoss {loss.item():.4}], [TrnAcc {tacc:.4}]')\n",
    "                tracker.iter_update(loss.item(),tacc)\n",
    "                \n",
    "            break\n",
    "              \n",
    "              \n",
    "class StatTracker:\n",
    "    def __init__(self):\n",
    "        self.iter_train_losses = []\n",
    "        self.iter_train_acc = []\n",
    "        self.full_train_acc = []\n",
    "        self.full_val_acc = []\n",
    "    def iter_update(self, tloss, tacc):\n",
    "        self.iter_train_losses.append(tloss)\n",
    "        self.iter_train_acc.append(tacc)\n",
    "    def full_update(self, tacc, vacc):\n",
    "        self.full_train_acc.append(tacc)\n",
    "        self.full_val_acc.append(vacc)\n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine tune (1) DenseNet (2) VGG.\n",
    "Record statistics every epoch.\n",
    "\"\"\"\n",
    "def train_models():\n",
    "    # Data Handling\n",
    "    train_loader = DataLoader(TRAIN_SET,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0)\n",
    "    val_loader = DataLoader(VAL_SET,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            num_workers=0)\n",
    "    trackers = []\n",
    "    \n",
    "    # Train\n",
    "    for modelname in MODEL_NAMES:\n",
    "        model_ft, input_size = initialize_model(modelname, \n",
    "                                                len(CLASSES), \n",
    "                                                feature_extract=False, \n",
    "                                                use_pretrained=True)\n",
    "        model = model_ft.to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "        tracker = StatTracker()\n",
    "        \n",
    "        train_model(train_loader,\n",
    "                    model,\n",
    "                    criterion,\n",
    "                    optimizer,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    tracker=tracker)\n",
    "        trackers.append(tracker)\n",
    "        torch.save({'epoch': NUM_EPOCHS,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict()}, \n",
    "                    f'./{modelname}-ep{NUM_EPOCHS}.pth')\n",
    "    \n",
    "    with open('stats.pkl', 'wb') as f:\n",
    "        pickle.dump(trackers, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Training Epoch 1\n",
      "========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
